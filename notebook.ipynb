{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision, torchinfo, torchmetrics\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os, glob, zipfile\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "class Custom_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,file_list):\n",
    "        self.file_list = file_list\n",
    "        self.transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((224, 224)), # IMPORTANT SIZE OF IMAGE (224, 224) or (256,256)\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        self.filelength = len(self.file_list)\n",
    "        return self.filelength\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_path        = self.file_list[idx]\n",
    "        img             = Image.open(img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        label = img_path.split('/')[-1].split('.')[0]\n",
    "        if label == 'dog':\n",
    "            label=1\n",
    "        elif label == 'cat':\n",
    "            label=0\n",
    "\n",
    "        return img_transformed,label\n",
    "\n",
    "# zip_files = ['train.zip', 'test.zip']\n",
    "# for zip_file in zip_files:\n",
    "#     with zipfile.ZipFile(\"../input/dogs-vs-cats-redux-kernels-edition/{}\".format(zip_file),\"r\") as z:\n",
    "#         z.extractall(\".\")\n",
    "#         print(\"{} unzipped\".format(zip_file))\n",
    "\n",
    "train_file_names_list = glob.glob(os.path.join(\"../working/train\",'*.jpg'))\n",
    "test_file_names_list  = glob.glob(os.path.join(\"../working/test\", '*.jpg'))\n",
    "\n",
    "train_list, val_list  = train_test_split(train_file_names_list, test_size=0.2)\n",
    "\n",
    "train_dataset = Custom_Dataset(train_list)\n",
    "val_dataset   = Custom_Dataset(val_list)\n",
    "\n",
    "training_dataloader    = torch.utils.data.DataLoader(dataset = train_dataset, batch_size=32, shuffle=True )\n",
    "validation_dataloader  = torch.utils.data.DataLoader(dataset = val_dataset  , batch_size=32, shuffle=False)\n",
    "\n",
    "assert next(iter(training_dataloader))   is not None\n",
    "assert next(iter(validation_dataloader)) is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "import lightning\n",
    "import torchmetrics\n",
    "\n",
    "class Lightning_Module(lightning.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.automatic_optimization = False\n",
    "        self.training_accuracy   = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.validation_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "  \n",
    "    def training_step (self, batch, batch_idx):\n",
    "        images_actual, labels_actual        = batch\n",
    "        predicted_logits  = self.model(images_actual)\n",
    "        labels_predicted  = torch.argmax(predicted_logits, dim = 1)\n",
    "\n",
    "        loss              = torch.nn.functional.cross_entropy(predicted_logits, labels_actual)\n",
    "        \n",
    "        optimizer         = self.optimizers()\n",
    "        optimizer.zero_grad()\n",
    "        self.manual_backward(loss)\n",
    "        optimizer.step()\n",
    "        \"\"\"\n",
    "        for individual_parameter in self.parameters():\n",
    "            individual_parameter = individual_parameter - individual_parameter.grad * learning_rate\n",
    "        \"\"\"\n",
    "        self.training_accuracy(labels_predicted, labels_actual)\n",
    "        self.log(\"train_loss\"     , loss                   , prog_bar = True)\n",
    "        self.log(\"train_accuracy\" , self.training_accuracy , prog_bar = True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step (self, batch, batch_idx):\n",
    "        images_actual, labels_actual        = batch\n",
    "        predicted_logits  = self.model(images_actual)\n",
    "        labels_predicted  = torch.argmax(predicted_logits, dim = 1)\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(predicted_logits, labels_actual)\n",
    "        self.validation_accuracy(labels_predicted, labels_actual)\n",
    "        self.log(\"validation_loss\"     , loss                     , prog_bar= False)\n",
    "        self.log(\"validation_accuracy\" , self.validation_accuracy , prog_bar= True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL ARCHITECTURE\n",
    "feature_extractor = nn.Sequential(\n",
    "    # Standard Input Size: 3, 224, 224\n",
    "    # Filter: UV Light filter on glasses is looking for UV lights to filter out or Filter in water purification, is looking for impurities\n",
    "    nn.Conv2d                           ( in_channels =  3, out_channels = 50, kernel_size = (3,3), padding=\"same\"), \n",
    "    nn.ReLU(), nn.MaxPool2d ((2,2), 2),                                           \n",
    "    # 112, 112\n",
    "    nn.Conv2d                           ( in_channels = 50, out_channels = 50, kernel_size = (3,3), padding=\"same\"),\n",
    "    nn.ReLU(), nn.MaxPool2d ((2,2), 2),\n",
    "    # 56, 56\n",
    "    nn.Conv2d                           ( in_channels = 50, out_channels = 50, kernel_size = (3,3), padding=\"same\"),\n",
    "    nn.ReLU(), nn.MaxPool2d ((2,2), 2),\n",
    "    # 28, 28\n",
    "    nn.Conv2d                           ( in_channels = 50, out_channels = 50, kernel_size = (3,3), padding=\"same\"),\n",
    "    nn.ReLU(), nn.MaxPool2d ((2,2), 2),\n",
    "    # 14, 14\n",
    "    nn.Conv2d                           ( in_channels = 50, out_channels = 512, kernel_size = (3,3), padding=\"same\"),\n",
    "    nn.ReLU(), nn.MaxPool2d ((2,2), 2),\n",
    "    # Standard Output Size: 512, 7, 7\n",
    "    # Total Features = 512 images of 7*7 pixel\n",
    ")\n",
    "\n",
    "decision_maker = nn.Sequential(\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features = 512*7*7 , out_features = 50), nn.ReLU(),\n",
    "    nn.Linear(in_features = 50      , out_features = 2) # 1 Neuron is for detecting Cat and 2nd Neuron is for detecting Dog\n",
    ")\n",
    "\n",
    "model = nn.Sequential(\n",
    "  feature_extractor,\n",
    "  decision_maker\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /Users/ajinkyak/Codes/Cats vs Dogs/lightning_logs\n",
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | model               | Sequential         | 1.6 M  | train\n",
      "1 | training_accuracy   | MulticlassAccuracy | 0      | train\n",
      "2 | validation_accuracy | MulticlassAccuracy | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.218     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ff582a021b494c9cd84f606b43a823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27895e4feae54b22a128e43b60d1d5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a668a3c05354743a82aa3a782d86bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74a45969f644bdbac0f8751b5ddfb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d468e1e83043d2bd0ee3223b499809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa20d52c52e4484bc6851044421b86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bff1f87a46845c5bf0e210883de0adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761413080ff5430db093f51f688faeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090f54a22a404d27b15a3fd78bbb7765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a745e0801d44388b4664a259e24ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25227f176f41472e92b33627c173bdbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ca3d8439b84329a633d955ff706e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "epochs  = 10\n",
    "lightning_model   = Lightning_Module(model)\n",
    "lightning_trainer = lightning.Trainer( max_epochs= epochs, log_every_n_steps= 50)\n",
    "\n",
    "lightning_trainer.fit(model=lightning_model, train_dataloaders= training_dataloader, val_dataloaders= validation_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trained_model_parameter_values.pth')\n",
    "\n",
    "# Load a trained model\n",
    "\n",
    "model.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=./lightning_logs "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
